{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabe506-a1a5-4c40-88f1-06a5cc7417ee",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Install required libraries\n",
    "try:\n",
    "    import duckduckgo_search\n",
    "    import transformers\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"Installing required packages...\")\n",
    "    # Install all required packages\n",
    "    subprocess.check_call(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
    "         \"duckduckgo-search\", \"transformers\", \"torch\"],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    )\n",
    "    print(\"Libraries installed successfully.\")\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SILVER_TABLE_NAME = \"silver_news\"\n",
    "GOLD_TABLE_NAME = \"gold_market_pulse\"\n",
    "\n",
    "try:\n",
    "    # 1. READ SILVER DATA\n",
    "    df_silver = spark.read.table(SILVER_TABLE_NAME)\n",
    "    \n",
    "    # 2. DEFINE THE AI MODEL (Pandas UDF)\n",
    "    @pandas_udf(StructType([\n",
    "        StructField(\"label\", StringType()),\n",
    "        StructField(\"score\", FloatType())\n",
    "    ]))\n",
    "    def sentiment_analysis_udf(text_series: pd.Series) -> pd.DataFrame:\n",
    "        # Load model inside function for distributed execution\n",
    "        pipe = pipeline(\n",
    "            \"sentiment-analysis\", \n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        )\n",
    "        \n",
    "        # Run sentiment analysis on batch\n",
    "        results = pipe(text_series.tolist(), truncation=True, max_length=512)\n",
    "        \n",
    "        # Convert to DataFrame with correct schema\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    # 3. APPLY THE MODEL\n",
    "    df_scored = df_silver.withColumn(\n",
    "        \"sentiment_result\", \n",
    "        sentiment_analysis_udf(col(\"snippet\"))\n",
    "    )\n",
    "    \n",
    "    # 4. FLATTEN RESULTS\n",
    "    df_gold = df_scored.select(\n",
    "        col(\"date\"),\n",
    "        col(\"competitor_tag\"),\n",
    "        col(\"source\"),\n",
    "        col(\"title\"),\n",
    "        col(\"url\"),\n",
    "        col(\"snippet\"),\n",
    "        col(\"sentiment_result.label\").alias(\"sentiment_label\"),\n",
    "        col(\"sentiment_result.score\").alias(\"confidence_score\")\n",
    "    )\n",
    "    \n",
    "    # 5. SAVE TO GOLD\n",
    "    df_gold.write.mode(\"overwrite\").format(\"delta\").saveAsTable(GOLD_TABLE_NAME)\n",
    "    \n",
    "    # Prepare pipeline output\n",
    "    record_count = df_gold.count()\n",
    "    result = {\n",
    "        \"status\": \"success\",\n",
    "        \"records_analyzed\": record_count,\n",
    "        \"table_name\": GOLD_TABLE_NAME,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Exit with JSON for pipeline\n",
    "    mssparkutils.notebook.exit(json.dumps(result))\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors gracefully\n",
    "    error_result = {\n",
    "        \"status\": \"failed\",\n",
    "        \"error\": str(e),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    mssparkutils.notebook.exit(json.dumps(error_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de093fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    date, \n",
    "    competitor_tag, \n",
    "    sentiment_label, \n",
    "    confidence_score, \n",
    "    snippet \n",
    "FROM gold_market_pulse \n",
    "ORDER BY date DESC \n",
    "LIMIT 10"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "44aa9b25-2bd6-4716-80b7-1a3f6d81a778",
    "default_lakehouse_name": "Lh_Market_Pulse",
    "default_lakehouse_workspace_id": "230d9539-aa80-4ea1-847e-f9acc0f18dd3",
    "known_lakehouses": [
     {
      "id": "44aa9b25-2bd6-4716-80b7-1a3f6d81a778"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
